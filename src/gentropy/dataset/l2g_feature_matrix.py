"""Feature matrix of study locus pairs annotated with their functional genomics features."""

from __future__ import annotations

from dataclasses import dataclass, field
from functools import reduce
from typing import TYPE_CHECKING, Type

from gentropy.common.schemas import parse_spark_schema
from gentropy.common.spark_helpers import convert_from_long_to_wide
from gentropy.dataset.dataset import Dataset
from gentropy.method.l2g.feature_factory import ColocalisationFactory, StudyLocusFactory

if TYPE_CHECKING:
    from pyspark.sql.types import StructType

    from gentropy.dataset.colocalisation import Colocalisation
    from gentropy.dataset.study_index import StudyIndex
    from gentropy.dataset.study_locus import StudyLocus
    from gentropy.dataset.v2g import V2G


@dataclass
class L2GFeatureMatrix(Dataset):
    """Dataset with features for Locus to Gene prediction.

    Attributes:
        features_list (list[str] | None): List of features to use. If None, all possible features are used.
        fixed_cols (list[str]): Columns that should be kept fixed in the feature matrix, although not considered as features.
        mode (str): Mode of the feature matrix. Defaults to "train". Can be either "train" or "predict".
    """

    features_list: list[str] | None = None
    fixed_cols: list[str] = field(default_factory=lambda: ["studyLocusId", "geneId"])
    mode: str = "train"

    def __post_init__(self: L2GFeatureMatrix) -> None:
        """Post-initialisation to set the features list. If not provided, all columns except the fixed ones are used.

        Raises:
            ValueError: If the mode is neither 'train' nor 'predict'.
        """
        if self.mode not in ["train", "predict"]:
            raise ValueError("Mode should be either 'train' or 'predict'")
        if self.mode == "train":
            self.fixed_cols = self.fixed_cols + ["goldStandardSet"]
        self.features_list = self.features_list or [
            col for col in self._df.columns if col not in self.fixed_cols
        ]
        self.validate_schema()

    @classmethod
    def generate_features(
        cls: Type[L2GFeatureMatrix],
        features_list: list[str],
        credible_set: StudyLocus,
        study_index: StudyIndex,
        variant_gene: V2G,
        colocalisation: Colocalisation,
    ) -> L2GFeatureMatrix:
        """Generate features from the gentropy datasets.

        Args:
            features_list (list[str]): List of features to generate
            credible_set (StudyLocus): Credible set dataset
            study_index (StudyIndex): Study index dataset
            variant_gene (V2G): Variant to gene dataset
            colocalisation (Colocalisation): Colocalisation dataset

        Returns:
            L2GFeatureMatrix: L2G feature matrix dataset

        Raises:
            ValueError: If the feature matrix is empty
        """
        if features_dfs := [
            # Extract features
            ColocalisationFactory._get_max_coloc_per_credible_set(
                colocalisation,
                credible_set,
                study_index,
            ).df,
            StudyLocusFactory._get_tss_distance_features(credible_set, variant_gene).df,
            StudyLocusFactory._get_vep_features(credible_set, variant_gene).df,
        ]:
            fm = reduce(
                lambda x, y: x.unionByName(y),
                features_dfs,
            )
        else:
            raise ValueError("No features found")

        # raise error if the feature matrix is empty
        return cls(
            _df=convert_from_long_to_wide(
                fm, ["studyLocusId", "geneId"], "featureName", "featureValue"
            ),
            _schema=cls.get_schema(),
            features_list=features_list,
        )

    @classmethod
    def get_schema(cls: type[L2GFeatureMatrix]) -> StructType:
        """Provides the schema for the L2gFeatureMatrix dataset.

        Returns:
            StructType: Schema for the L2gFeatureMatrix dataset
        """
        return parse_spark_schema("l2g_feature_matrix.json")

    def merge_features_in_efo(
        self: L2GFeatureMatrix,
        features: list[str],
        credible_set: StudyLocus,
        study_index: StudyIndex,
        max_distance: int = 500000,
    ) -> L2GFeatureMatrix:
        """Merge studyLocusId-to-geneId pairings in the feature matrix, filling in missing features.

        Args:
            features (list[str]): List of features to merge
            credible_set (StudyLocus): Credible set dataset
            study_index (StudyIndex): Study index dataset
            max_distance (int): Maximum allowed base pair distance for grouping variants. Default is 500,000.

        Returns:
            L2GFeatureMatrix: L2G feature matrix dataset
        """
        from pyspark.sql import functions as f
        from pyspark.sql.window import Window

        efo_df = (
            credible_set.df.join(study_index.df, on="studyId", how="inner").select(
                "studyId",
                "studyLocusId",
                "variantId",
                f.explode(study_index.df["traitFromSourceMappedIds"]).alias(
                    "efo_terms"
                ),
            )
        ).join(
            self._df,
            on="studyLocusId",
            how="inner",
        )

        efo_df = efo_df.withColumn(
            "chromosome", f.split(f.col("variantId"), "_").getItem(0)
        )
        efo_df = efo_df.withColumn(
            "position", f.split(f.col("variantId"), "_").getItem(1).cast("long")
        )

        window_spec = Window.partitionBy("efo_terms", "geneId", "chromosome").orderBy(
            "position"
        )

        efo_df = efo_df.withColumn(
            "position_diff", f.col("position") - f.lag("position", 1).over(window_spec)
        )
        efo_df = efo_df.withColumn(
            "group",
            f.sum(f.when(f.col("position_diff") > max_distance, 1).otherwise(0)).over(
                window_spec
            ),
        )

        max_df = efo_df.groupBy("efo_terms", "geneId", "group").agg(
            *[f.max(col).alias(f"{col}_max") for col in features]
        )

        imputed_df = efo_df.join(
            max_df, on=["efo_terms", "geneId", "group"], how="left"
        )

        for col in features:
            imputed_df = imputed_df.withColumn(col, f.col(f"{col}_max")).drop(
                f"{col}_max"
            )

        self.df = imputed_df.drop(
            "efo_terms",
            "studyId",
            "chromosome",
            "position",
            "position_diff",
            "group",
            "variantId",
        ).distinct()

        return self

    def calculate_feature_missingness_rate(
        self: L2GFeatureMatrix,
    ) -> dict[str, float]:
        """Calculate the proportion of missing values in each feature.

        Returns:
            dict[str, float]: Dictionary of feature names and their missingness rate.

        Raises:
            ValueError: If no features are found.
        """
        total_count = self._df.count()
        if not self.features_list:
            raise ValueError("No features found")

        return {
            feature: (
                self._df.filter(
                    (self._df[feature].isNull()) | (self._df[feature] == 0)
                ).count()
                / total_count
            )
            for feature in self.features_list
        }

    def fill_na(
        self: L2GFeatureMatrix, value: float = 0.0, subset: list[str] | None = None
    ) -> L2GFeatureMatrix:
        """Fill missing values in a column with a given value.

        Args:
            value (float): Value to replace missing values with. Defaults to 0.0.
            subset (list[str] | None): Subset of columns to consider. Defaults to None.

        Returns:
            L2GFeatureMatrix: L2G feature matrix dataset
        """
        self.df = self._df.fillna(value, subset=subset)
        return self

    def select_features(
        self: L2GFeatureMatrix,
        features_list: list[str] | None,
    ) -> L2GFeatureMatrix:
        """Select a subset of features from the feature matrix.

        Args:
            features_list (list[str] | None): List of features to select

        Returns:
            L2GFeatureMatrix: L2G feature matrix dataset

        Raises:
            ValueError: If no features have been selected.
        """
        if features_list := features_list or self.features_list:
            self.df = self._df.select(self.fixed_cols + features_list)
            return self
        raise ValueError("features_list cannot be None")
